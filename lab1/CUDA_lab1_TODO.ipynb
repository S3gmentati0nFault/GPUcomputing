{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab1_TODO.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["9YGa6hXkx77o","F9PmBZql0ow4","XX4ILmhgLNUZ","7yZYCuVxpngN","mB94Ce6kViOj"],"mount_file_id":"1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL","authorship_tag":"ABX9TyNGCTXvYeGHRgt0EfR8Zydf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9YGa6hXkx77o"},"source":["#  ✔  Google Colaboratory (colab)"]},{"cell_type":"markdown","metadata":{"id":"F-lZoo4TstJn"},"source":["[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zfPMRBrqzjjb"},"source":["##Upload/download files\n","\n","\n","Once you open a **Google Colab notebook**, it creates a **virtual machine** instance on a Google Cloud Platform. To **upload** files from your local machine to Colab virtual storage, use `upload` option from the left sidebar. To **download** files from Colab's virtual storage to your local machine, right-click on a file and then select `Download`. You can also mount your google drive: once you click on **MOUNT DRIVE** in the left sidebar, it will insert a code cell into your notebook that you'll need to run to mount your google drive (it will ask for your authorization). Another way to download files (without mounting a google drive) is to use a `!gdown` or `!wget` commands (more details in the [Shell commands](#scrollTo=JrF12-bqPKPm) section)<br><br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1CRjolVrVbEboNPLVVw-c_AtsBBcSou1Z\" width=800 px><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZvWtrdMfxQD8"},"source":["## Notebook rules\n","\n","Some basic notebook rules:\n","\n","\n","1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n","2.   Re-executing a cell will reset it (any input will be lost).\n","3.   Execute cells TOP TO BOTTOM.\n","5. Notebooks are saved to your Google Drive \n","6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n","7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."]},{"cell_type":"markdown","metadata":{"id":"ulev4sV3wc-T"},"source":["## Shell commands"]},{"cell_type":"markdown","metadata":{"id":"fS67zRIavQtS"},"source":["The command `uname` displays the information about the system.\n","\n","* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname, \n","kernel release date, kernel version, machine hardware name, hardware platform, operating system\n","."]},{"cell_type":"code","metadata":{"id":"PT7Umr53u2Qz"},"source":["!uname -a && cat /etc/*release"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1h8YWW1RzEN"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qM1A-h_mnC_"},"source":["If you play with IPython's shell commands for a while, you might notice that you cannot use `!cd` to navigate the filesystem:"]},{"cell_type":"code","metadata":{"id":"u1R7Ci1nml4P"},"source":["! cd /content/drive/MyDrive/GPU_computing/github/GPUcomputing/\n","! pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wt_VrzenkgM"},"source":["The reason is that shell commands in the notebook are executed in a temporary subshell. If you'd like to change the working directory in a more enduring way, you can use the `%cd` **magic command**:"]},{"cell_type":"code","metadata":{"id":"ZS7RrfYvfceJ"},"source":["% cd /content/drive/MyDrive/GPU_computing/github/GPUcomputing/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iseDMLyXT7wG"},"source":["!ls -la lab1/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWIzTy57JLBW"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ✔ CUDA zone"]},{"cell_type":"markdown","metadata":{"id":"Ur7-3SF3h4vy"},"source":["## How to use accelerated hardware\n","\n","To change hardware runtime you just have to navigate from `Runtime -> change runtime` type and select your preferred accelerated hardware type **GPU** or **TPU**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTRXba1Msgq2"},"source":["## NVIDIA System Management Interface (nvidia-smi) \n","\n","The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices. \n","\n","This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n","\n","For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))"]},{"cell_type":"code","metadata":{"id":"NlXMCnBVBkeE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nxmU0pZJE7R"},"source":["How to remove cuda completely from ubuntu... and install another version"]},{"cell_type":"code","metadata":{"id":"MLlLB3gXDKBr"},"source":["!apt-get --purge remove cuda nvidia* libnvidia-*\n","!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","!apt-get remove cuda-*\n","!apt autoremove\n","!apt-get update"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XX4ILmhgLNUZ"},"source":["## CUDA Toolkit\n","Develop, Optimize and Deploy GPU-Accelerated Apps\n","The NVIDIA® CUDA® Toolkit provides a development environment for creating high performance GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime library to build and deploy your application on major architectures including x86, Arm and POWER.\n","\n","Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.\n","[cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"38jSDwugDYKB"},"source":["!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","!wget https://developer.download.nvidia.com/compute/cuda/11.2.1/local_installers/cuda-repo-ubuntu1804-11-2-local_11.2.1-460.32.03-1_amd64.deb\n","!dpkg -i cuda-repo-ubuntu1804-11-2-local_11.2.1-460.32.03-1_amd64.deb\n","!apt-key add /var/cuda-repo-ubuntu1804-11-2-local/7fa2af80.pub\n","!apt-get update\n","!apt-get -y install cuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vifkJTru0yOg"},"source":["!ls -la /usr/local"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OR8MTAveVNmu"},"source":["Now you can check your CUDA installation by running the command given below :\n"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"twcqMEhVVMr8"},"source":["## Save and compile\n","\n","To save the `.cu` file and compile it using the command-line syntax *define* the the magic cell:\n","```\n","%%cuda --name filename.cu \n","```\n","The source file will be saved under the directory `src/`\n","\n","Otherwise, you can use standard the macig command:\n","```\n","%%writefile <path-to-file->/filename.cu \n","```"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"Uvnxz_D5WMnt"}},{"cell_type":"markdown","metadata":{"id":"7yZYCuVxpngN"},"source":["#  ✔ VS code on Colab"]},{"cell_type":"markdown","metadata":{"id":"7fRcctBZqHh9"},"source":["How to use [VS Code](https://code.visualstudio.com/) on Google Colab as an editor to write code and run experiments on the Colab VM. With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. \n","\n","\n","---\n","\n","\n","1.  Install the colab-code package using the following command:\n","\n"," ```pip install colabcode```\n","\n","2.  Import `ColabCode` class from the package and launch it:\n","```\n","from colabcode import ColabCode \n","ColabCode()\n","```\n","3. You will get the `ngrok` URL in the output. Click the link and a login page will open in a new tab.\n","\n","> ![alt text](https://drive.google.com/uc?id=1KK8VY85vjZ_WDxWIFaZcn1Znhf6XjSqK)\n","\n","4. You will get access to the VSCode editor interface and can use it to work on CUDA/C++ files\n","> ![alt text](https://drive.google.com/uc?id=1SmMmzAxI_mCg2bcwwRfqN5-dGzg3F9z-)\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DKHvaMw3puK7"},"source":["# 1. Install the colab-code package...\n","!pip install colabcode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIGztaKepvqO"},"source":["# 2. Import and launch...\n","from colabcode import ColabCode\n","ColabCode()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  ★ Hello World!"],"metadata":{"id":"mB94Ce6kViOj"}},{"cell_type":"code","metadata":{"id":"RlbVvBaXCHBs"},"source":["%%cuda --name hello.cu\n","#include <stdio.h>\n","#include <iostream>\n","\n","using namespace std;\n","\n","__global__ void helloFromGPU (void) {\n","    printf(\"Hello World from GPU!\\n\");\n","}\n","\n","int main(void) {\n","    // # hello from GPU \n","    cout << \"Hello World from CPU!\" << endl;\n","    cudaSetDevice(1);\n","    helloFromGPU <<<1, 10>>>();\n","    cudaDeviceSynchronize();\n","    return 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OURqX6K2isWG"},"source":["compile..."]},{"cell_type":"code","metadata":{"id":"JjFZp49LcO-F"},"source":["%%shell\n","\n","nvcc -arch=sm_37 src/hello.cu -o hello"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Hvii50CGGfP"},"source":["and execute..."]},{"cell_type":"code","metadata":{"id":"kMEGfjJMcX_e"},"source":["%%shell\n","\n","./hello"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c9DOGMoaV-rq"},"source":["##Edit, compile & exec\n","\n","With the magic cell \n","```\n","%cu\n","```\n","you can edit, compile (only one file at a time) and execute direcly the code by executing the cell..."]},{"cell_type":"code","metadata":{"id":"6DxzZ-xZWMoX"},"source":["%%cu \n","#include <stdio.h>\n","\n","__global__ void helloFromGPU (void) {\n","    printf(\"Hello World from GPU!\\n\");\n","}\n","\n","int main(void) {\n","    // # hello from GPU\n","    printf(\"Hello World from CPU!\\n\");\n","    cudaSetDevice(1);\n","    helloFromGPU <<<1,10>>>();\n","    cudaDeviceSynchronize();\n","    return 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bll8pe7Fj3y"},"source":["#  ★  MQDB: Matrici quadrate diagonali a blocchi"]},{"cell_type":"code","metadata":{"id":"KMp_CpISiVvH"},"source":["#@title working directory: **MQDB-CUDA**\n","%mkdir -p MQDB\n","%ls -la"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Libreria MQDB: collezione di funzioni per oerare sui tipi MQDB "],"metadata":{"id":"humax_OpcNhe"}},{"cell_type":"code","metadata":{"id":"mbG20QCi7G6T"},"source":["%%writefile MQDB/mqdb.h\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <math.h>\n","#include <sys/time.h>\n","\n","#ifndef MQDB_H\n","#define MQDB_H\n","\n","#define randu() ((float)rand() / (float) RAND_MAX)\n","#define abs(x) ((x)<0 ? (-x) : (x))\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","typedef struct MQDB {\n","\tchar desc[100];   // description\n","\tint nBlocks;      // num. of blocks\n","\tint *blkSize;     // block dimensions\n","\tfloat *elem;       // elements in row-major order\n","\tulong nElems;     // actual number of elements\n","} mqdb;\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","// # function prototypes #\n","int genRandDims(mqdb*, uint, uint);\n","void fillBlocks(mqdb*, uint, uint, char, float);\n","mqdb mqdbConst(uint, uint, uint, float);\n","void mqdbProd(mqdb, mqdb, mqdb);\n","void matProd(mqdb, mqdb, mqdb);\n","void checkResult(mqdb, mqdb);\n","void mqdbDisplay(mqdb);\n","\n","inline double seconds() {\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiDq208h8qmn"},"source":["%%writefile MQDB/mqdb.cpp\n","\n","#include \"mqdb.h\"\n","\n","/**\n"," * random generate block dimensions\n"," */\n","int genRandDims(mqdb *M, uint n, uint k) {\n","\n","\tif (n == 0 || k == 0 || k > n) {\n","\t\tprintf(\"error: n,k must be positive and n > k!\\n\");\n","\t\treturn(-1);\n","\t}\n","\t// random generation of block sizes\n","\tM->blkSize = (int *) malloc(k * sizeof(int));\n","\tint sum = 0;\n","\tint r;\n","\tfloat mu = 2.0f * (float) n / (float) k;\n","\tfor (int i = 0; i < k - 1; i++) {\n","\t\t// expected value E[block_size] = n/k\n","\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n","\t\tif (!r)\n","\t\t\tr += 1;\n","\t\tM->blkSize[i] = r;\n","\t\tsum += r;\n","\t}\n","\tM->blkSize[k - 1] = n - sum;\n","\treturn(0);\n","}\n","\n","/**\n"," * # fill blocks either random or constant #\n"," */\n","void fillBlocks(mqdb *M, uint n, uint k, char T, float c) {\n","\t//mat size n*n\n","\tM->elem = (float *) calloc(n * n, sizeof(float));\n","\tM->nElems = 0;\n","\tint offset = 0;\n","\t// # loop on blocks #\n","\tfor (int i = 0; i < k; i++) {\n","\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n","\t\t\tfor (int k = 0; k < M->blkSize[i]; k++)\n","\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n","\t\t\t\telse if (T == 'R') \t// random fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = randu();\n","\t\toffset += M->blkSize[i];\n","\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n","\t}\n","\t// # set description #\n","\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d, blk sizes: \",n,k);\n","}\n","\n","/**\n"," * rand_gen_mqdb: mqdb  type returned\n"," *                n     square matrix size\n"," *                k     number of blocks\n"," *                seed  seed for random generator\n"," */\n","mqdb genRandMat(unsigned n, unsigned k, unsigned seed) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// # random fill mat entries #\n","\tfillBlocks(&M, n, k, 'R', 0.0);\n","\n","\treturn M;\n","}\n","\n","/**\n"," * const_mqdb: mqdb  is the type returned\n"," *                n     is the square matrix size\n"," *                k     is the number of blocks\n"," *                seed  is the seed for random generator\n"," *                c   \tis the constant value assigned\n"," */\n","mqdb mqdbConst(uint n, uint k, uint seed, float c) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// fill mat entries with a constant\n","\tfillBlocks(&M, n, k, 'C', c);\n","\n","\treturn M;\n","}\n","\n","/*\n"," * standard (naive) matrix product on host\n"," */\n","void matProd(mqdb A, mqdb B, mqdb C) {\n","\tint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\n","\tfor (uint r = 0; r < n; r++)\n","\t\tfor (uint c = 0; c < n; c++) {\n","\t\t\tdouble sum = 0;\n","\t\t\tfor (uint l = 0; l < n; l++){\n","\t\t\t\tdouble a = A.elem[r * n + l];\n","\t\t\t\tdouble b = B.elem[l * n + c];\n","\t\t\t\tsum += a*b;\n","\t\t\t}\n","\t\t\tC.elem[r * n + c] = (float)sum;\n","\t\t}\n","}\n","\n","/*\n"," * elementwise comparison between two mqdb\n"," */\n","void checkResult(mqdb A, mqdb B) {\n","\tdouble epsilon = 1.0E-8;\n","\tbool match = 1;\n","\tint n = 0;\n","\tfor (int i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\tfor (int i = 0; i < n * n; i++) {\n","\t\tif (abs(A.elem[i] - B.elem[i]) > epsilon) {\n","\t\t\tmatch = 0;\n","\t\t\tprintf(\"   * Arrays do not match!\\n\");\n","\t\t\tprintf(\"     gpu: %2.2f,  host: %2.2f at current %d\\n\", A.elem[i],\n","\t\t\t\t\tB.elem[i], i);\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","\tif (match)\n","\t\tprintf(\"   Arrays match\\n\\n\");\n","}\n","/*\n"," * print mqdb\n"," */\n","void mqdbDisplay(mqdb M) {\n","\tint n = 0;\n","\tprintf(\"%s\", M.desc);\n","\tfor (int j = 0; j < M.nBlocks; j++) {\n","\t\tprintf(\"%d  \", M.blkSize[j]);\n","\t\tn += M.blkSize[j];\n","\t}\n","\tprintf(\"\\n\");\n","\tfor (int j = 0; j < n * n; j++) {\n","\t\tif (M.elem[j] == 0)\n","\t\t\tprintf(\"------\");\n","\t\telse\n","\t\t\tprintf(\"%5.2f \", M.elem[j]);\n","\t\tif ((j + 1) % n == 0)\n","\t\t\tprintf(\"\\n\");\n","\t}\n","\tprintf(\"\\n\");\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TODO:\n","\n","Sviluppare una funzione per effettuare il prodotto ottimizzato (ristretto ai soli blocchi sulla diagonale) tra due matrici $C=A*B$ ti tipo MQDB, aventi uguale dimensione (stesso lato $n$ e ugual dimensione $n_i$ dei $k$ blocchi $k_i$ sulla diagonale)"],"metadata":{"id":"BWkjCoM0ckzF"}},{"cell_type":"code","source":["%%writefile MQDB/prod_mqdb.cpp\n","\n"],"metadata":{"id":"BtdrHhgOcoJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main"],"metadata":{"id":"1CSpZ6wplPmy"}},{"cell_type":"code","metadata":{"id":"r19AgzDRBJh3"},"source":["%%writefile MQDB/main.cpp\n","#include <sys/time.h>\n","#include \"mqdb.h\"\n","\n","/*\n"," * main function\n"," */\n","int main(void) {\n","\tuint n = 2*1024;      // matrix size\n","  uint k = 10;          // num of blocks\n","\tmqdb A, B, C, C1;     // mqdb host matrices\n","\n","\t// fill in\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\tprintf(\"CPU mat product...\\n\");\n","\tdouble start = seconds();\n","  matProd(A, B, C);\n","\tdouble CPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","  printf(\"CPU MQDB product...\\n\");\n","\tstart = seconds();\n","  mqdbProd(A, B, C);\n","\tCPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kWihzIB84j1"},"source":["# Compilazione ed esecuzione\n","!g++ MQDB/prod_mqdb.cpp MQDB/main.cpp MQDB/mqdb.cpp -o main\n","!./main"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Report\n","\n","Riportare i tempi di esecuzione per \n","\n","$k = 10$\n","* n = 1024, time = \n","* n = 2048, time = \n","* n = 4096, time = \n","\n","$k = 20$\n","* n = 1024, time = \n","* n = 2048, time = \n","* n = 4096, time = "],"metadata":{"id":"JrC7365ckKJ6"}},{"cell_type":"code","source":[""],"metadata":{"id":"NQT8OVjhlDJA"},"execution_count":null,"outputs":[]}]}