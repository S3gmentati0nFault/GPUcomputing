{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab9_TODO.ipynb","private_outputs":true,"provenance":[{"file_id":"1tnLuQH7o0Bk_8YR-gKq0-dZn_zsTGALa","timestamp":1652096968562}],"collapsed_sections":["WoJbB3T5Vkw-","zs_a5Vuimily","iUYP4kCJhEIx","lAVvcKOX_DU0","vXUIQkZLCTcG","SOFMQZAkjlLW","l1rqW0qCN4YD"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyO3wCDx+IWGPg7BU4Ot0USu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 9 - CUDA Libraries**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"WoJbB3T5Vkw-"},"source":["# ▶️ CUDA setup"]},{"cell_type":"code","metadata":{"id":"Fht2Wy8wVkxJ"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jP2H_YJVkxJ"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)"],"metadata":{"id":"VKbaxH9wWosO"}},{"cell_type":"markdown","metadata":{"id":"_cGSqZovVkxK"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RCVhMkqYVkxK"},"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6PDOytTVkxK"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bash and data setup"],"metadata":{"id":"cReFlD-VRfZe"}},{"cell_type":"code","source":["#@title Bash setup\n","%%writefile /root/.bashrc\n","\n","# If not running interactively, don't do anything\n","[ -z \"$PS1\" ] && return\n","\n","# don't put duplicate lines in the history. See bash(1) for more options\n","# ... or force ignoredups and ignorespace\n","HISTCONTROL=ignoredups:ignorespace\n","\n","# append to the history file, don't overwrite it\n","shopt -s histappend\n","\n","# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\n","HISTSIZE=10000\n","HISTFILESIZE=20000\n","\n","# check the window size after each command and, if necessary,\n","# update the values of LINES and COLUMNS.\n","shopt -s checkwinsize\n","\n","# make less more friendly for non-text input files, see lesspipe(1)\n","[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n","\n","PS1='\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\n","\n","# enable color support of ls and also add handy aliases\n","if [ -x /usr/bin/dircolors ]; then\n","    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n","    alias ls='ls --color=auto'\n","    #alias dir='dir --color=auto'\n","    #alias vdir='vdir --color=auto'\n","\n","    alias grep='grep --color=auto'\n","    alias fgrep='fgrep --color=auto'\n","    alias egrep='egrep --color=auto'\n","fi\n","\n","# some more ls aliases\n","alias ll='ls -lF'\n","alias la='ls -A'\n","alias l='ls -CF'\n","\n","# path setup\n","export PATH=\"./:/usr/local/cuda/bin:$PATH\""],"metadata":{"cellView":"form","id":"O8ICSyy8_GEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!source /root/.bashrc"],"metadata":{"id":"QxIfKO3Ghf7g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clone GPUcomputing site on github..."],"metadata":{"id":"IYG8Cv4bTzyI"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"E7jZmHjCT0vu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define some paths..."],"metadata":{"id":"ZarLje6wR_Og"}},{"cell_type":"code","source":["# path setup\n","!mkdir -p /content/GPUcomputing/lab9\n","%cd /content/GPUcomputing/lab9\n","!mkdir -p cublas\n","!mkdir -p curand\n","!mkdir -p cufft"],"metadata":{"id":"tC-AaOJlkLOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ▶️ VS Code on Colab"],"metadata":{"id":"zs_a5Vuimily"}},{"cell_type":"code","source":["#@title Colab-ssh tunnel\n","#@markdown Execute this cell to open the ssh tunnel. Check [colab-ssh documentation](https://github.com/WassimBenzarti/colab-ssh) for more details.\n","\n","# Install colab_ssh on google colab\n","!pip install colab_ssh --upgrade\n","\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","ssh_tunnel_password = \"gpu\" #@param {type: \"string\"}\n","launch_ssh_cloudflared(password=ssh_tunnel_password)\n","\n","# Optional: if you want to clone a Github or Gitlab repository\n","repository_url=\"https://github.com/giulianogrossi/GPUcomputing\" #@param {type: \"string\"}\n","init_git_cloudflared(repository_url)"],"metadata":{"id":"BCf9JxqphHAp","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ▶️ DeviceQuery"]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# DeviceQuery dell'attuale device (su Colab!)\n","!nvcc /content/GPUcomputing/utils/deviceQuery.cu -o deviceQuery\n","!./deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check whether the device can transfer in both directions simultaneously"],"metadata":{"id":"J-EcbVrAYlfS"}},{"cell_type":"code","source":["%%cu\n","#include <stdio.h>\n","\n","int main(void) {\n","\n","  cudaDeviceProp dProp;\n","\tcudaGetDeviceProperties(&dProp, 0);\n","\n","  // Shows whether the device can transfer in both directions simultaneously\n","  printf(\"Device %s capable of simultaneous CPU-to-GPU and GPU-to-CPU datatransfers\\n\", dProp.deviceOverlap ? \"IS\": \"NOT\");\n","  return 0;\n","}"],"metadata":{"id":"esYDQTl-Yg3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAVvcKOX_DU0"},"source":["# ✅ cuBLAS"]},{"cell_type":"code","metadata":{"id":"OH6TuWnB-_0M"},"source":["%%writefile cublas/mat_prod_cublas.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"cublas_v2.h\"\n","#include \"../../utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c) \n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define BLOCK_SIZE 4\n","#define M          (1<<12)\n","#define N          (1<<12)\n","#define P          (1<<12)\n","\n","void generate_random_vector(int, float**);\n","void generate_random_dense_matrix_Row_Maj(int, int, float**);\n","void generate_random_dense_matrix_Col_Maj(int, int, float**);\n","void plot_mat_Row_Maj(int, int, float*, char);\n","void plot_mat_Col_Maj(int, int, float*, char);\n","__global__ void matProdSMEMstatic(float*, float*, float*, int, int, int);\n","\n","/*\n"," * comparison between standard prod kernel and cuBLAS\n"," */\n","int main(int argc, char **argv) {\n","\n","\tint n = N, m = M, p = P;\n","\tfloat *A, *d_A;  // matrix M x N  (row M, col N)\n","\tfloat *B, *d_B;  // matrix N x P  (row N, col P)\n","\tfloat *C, *d_C;  // matrix M x P, C = A*B\n","\tfloat *x, *d_x;  // vector N x 1 \n","\tfloat *y, *d_y;  // vector N x 1, y = A*x\n","\tfloat beta = 0.0f;\n","\tfloat alpha = 1.0f;\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate inputs\n","\tsrand(10);\n","\tgenerate_random_dense_matrix_Col_Maj(m, n, &A);\n","\tgenerate_random_dense_matrix_Col_Maj(n, p, &B);\n","\tgenerate_random_vector(n, &x);\n","\tgenerate_random_vector(n, &y);\n","\n","\tC = (float *) malloc(m * p * sizeof(float));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&d_A, m * n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_B, n * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_C, m * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_x, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_y, m * sizeof(float)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\t\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(m, n, sizeof(float), A, m, d_A, m));\n","\tCHECK_CUBLAS(cublasSetMatrix(n, p, sizeof(float), B, n, d_B, n));\n","\tCHECK_CUBLAS(cublasSetMatrix(m, p, sizeof(float), C, m, d_C, m));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(float), x, 1, d_x, 1));\n","\tCHECK_CUBLAS(cublasSetVector(m, sizeof(float), y, 1, d_y, 1));\n","\n","\t/***************************************************\n","\t *      Multipl. matrix-vector CUBLAS              *\n","\t ***************************************************/\n","\t\n","  printf(\"\\n**  Matrix-vector product...\\n\");\n","  printf(\"    y(%d x 1) = A(%d x %d) * x(%d x 1)\\n\",n,m,n,n);\n","\n","\tcudaEventRecord(start);\n","\tCHECK_CUBLAS(cublasSgemv(handle, CUBLAS_OP_N, m, n, &alpha, d_A, m, d_x, 1, &beta, d_y, 1));\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetVector(m, sizeof(float), d_y, 1, y, 1));\n","\n","\n","\t/**********************************************\n","\t *  Multiplic. matrix-matrix CUBLAS           *\n","\t **********************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","\n","  //plot_mat_Col_Maj(m, n, A, 'A');\n","  //plot_mat_Col_Maj(n, p, B, 'B');\n","\n","\tCHECK(cudaMemset(d_C, 0,  m * p *sizeof(float)));\n","\tCHECK(cudaEventRecord(start));\n","\tCHECK_CUBLAS(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, p, n, &alpha, d_A, m, d_B, n, &beta, d_C, m));\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetMatrix(m, p, sizeof(float), d_C, m, C, m));\n","\n","  //plot_mat_Col_Maj(m, p, C, 'C');\n","\n","\n","\t/*****************************************************\n","\t *  Multiplicat. matrix-matrix kernel ad-hoc         *\n","\t *****************************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product using ad-hoc kernel (with SMEM)...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","  \n","  float *A1, *B1; \n","  srand(10);\n","\tgenerate_random_dense_matrix_Row_Maj(m, n, &A1);\n","\tgenerate_random_dense_matrix_Row_Maj(n, p, &B1);\n","\n","  //plot_mat_Row_Maj(m, n, A1, 'A');\n","  //plot_mat_Row_Maj(n, p, B1, 'B');\n","\n","\t// copy matrices A and B to the GPU\n","\tCHECK(cudaMemcpy(d_A, A1, m * n * sizeof(float), cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpy(d_B, B1, n * p * sizeof(float), cudaMemcpyHostToDevice));\n","  CHECK(cudaMemset(d_C, 0.0f, m * p * sizeof(float)));\n","\n","\t// grid block dims = shared mem dims = BLOCK_SIZE\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((p + block.x - 1) / block.x, (m + block.y - 1) / block.y);\n","\tCHECK(cudaEventRecord(start));\n","\tmatProdSMEMstatic<<<grid, block>>>(d_A, d_B, d_C, n, m, p);\n","  CHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C, d_C, m * p * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  //plot_mat_Row_Maj(m, p, C, 'C');\n","  \n","\t// free memory\n","\tcudaFree(d_A);\n","\tcudaFree(d_B);\n","\tcudaFree(d_C);\n","\tcudaFree(d_x);\n","\tcudaFree(d_y);\n","\tCHECK_CUBLAS(cublasDestroy(handle));\n","\n","\treturn EXIT_SUCCESS;\n","}\n","\n","/*\n"," * Generate a vector of length N with random single-precision floating-point\n"," * values between 0 and 100.\n"," */\n","\n","void generate_random_vector(int n, float **x) {\n","\tfloat *z = (float *) malloc(sizeof(float) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (float)rand() / RAND_MAX;\n","\t*x = z;\n","}\n","\n","/*\n"," * Generate a matrix with M rows and N columns in column-major order. The matrix\n"," * will be filled with random single-precision floating-point values between 0 and 10\n"," */\n","void generate_random_dense_matrix_Col_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","  for (int c = 0; c < cols; ++c)\n","    for (int r = 0; r < rows; ++r){\n","      a[IDX2C(r,c,rows)] = val;\n","      val += 1;\n","    }\n","\t*A = a;\n","}\n","\n","void generate_random_dense_matrix_Row_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","\tfor (int r = 0; r < rows; r++)\n","\t\tfor (int c = 0; c < cols; c++) {\n","\t\t\ta[IDX2R(r,c,cols)] = val;\n","      val += 1;\n","\t\t}\n","\t*A = a;\n","}\n","\n","void plot_mat_Row_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,cols)]);\n","    printf(\"\\n\");\n","\t} \n","  printf(\"\\n\");\n","}\n","\n","void plot_mat_Col_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","  for(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","      printf(\"%4.1f \", A[IDX2C(r,c,rows)]);\n","    printf(\"\\n\");\n","  }\n","  printf(\"\\n\");\n","}\n","\n","\n","/*\n"," * Kernel for matrix product with static SMEM\n"," *      C   =   A   *   B\n"," *   (m x p) (m x n) (n x p)\n"," */\n","__global__ void matProdSMEMstatic(float* A, float* B, float* C, int n, int m, int p) {\n","\t// indexes\n","\tuint row = blockIdx.y * blockDim.y + threadIdx.y; // in [0..m]\n","\tuint col = blockIdx.x * blockDim.x + threadIdx.x; // in [0..p]\n","\n","\t// target: compute the right sum for the given row and col\n","\tfloat sum = 0.0;\n","\n","\t// static shared memory\n","\t__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];\n","\t__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];\n","\n","\t// loop over blocks from block row of matrix A and block column of matrix B\n","\tuint numBlocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","\n","\tfor (uint i = 0; i < numBlocks; i++) {\n","\n","\t\t// copy block from matrix to shared memory\n","\t\tuint r = i * BLOCK_SIZE + threadIdx.y;\n","\t\tuint c = i * BLOCK_SIZE + threadIdx.x;\n","\t\tAs[threadIdx.y][threadIdx.x] = A[IDX2R(row, c, n)];\n","\t\tBs[threadIdx.y][threadIdx.x] = B[IDX2R(r, col, p)];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on SMEM loading\n","\n","\t\tuint K = BLOCK_SIZE;\n","\t\tif (i == (numBlocks - 1)) \n","      K = n - i * BLOCK_SIZE;   // tune last block\n","\n","\t\t// compute this part of row-column product\n","\t\tfor (uint k = 0; k < K; k++)\n","\t\t\tsum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on prod over blocks\n","\t}\n","\n","\t// store computed element in matrix C\n","\tif (row < m && col < p)\n","\t\tC[row * p + col] = sum;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7G91KROXBScK"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_37 cublas/mat_prod_cublas.cu  -o prod -lcublas\n","!./prod"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 TODO"],"metadata":{"id":"sEN7QQnSxNca"}},{"cell_type":"code","source":["%%writefile cublas/CG.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <cublas_v2.h>\n","#include <cuda_runtime.h>\n","#include <cusparse.h>\n","#include \"../../utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c) \n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define N          (1<<3)\n","\n","void generate_random_vector(int, float**);\n","void generate_random_simmetric_matrix(int, float**);\n","void plot_mat(int, float*, char);\n","void plot_vec(int, float*, char); \n","\n","/*\n"," * This sample implements a conjugate gradient solver on GPU using CUBLAS\n"," */\n","int main(int argc, char **argv) {\n","  int n = N;\n","\tfloat *A, *dA;      // matrix N x N  (square)\n","\tfloat *x, *dx;      // vector N x 1 \n","\tfloat *b, *db;      // vector N x 1\n","\tfloat *dr, *dr1;    // vector N x 1\n","\tfloat *dp;          // vector N x 1\n","\tfloat *dAxp, *dAxr; // vector N x 1\n","\t\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate instance: matrix A and vector b\n","\tsrand(10);\n","\tgenerate_random_simmetric_matrix(n, &A);  // random symmetric matrix A\n","\tgenerate_random_vector(n, &b);            // random verctor b\n","\tgenerate_random_vector(n, &x);            // random initial solution\n","\tplot_mat(n, A,'A');\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dA, n * n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dx, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&db, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dr, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dr1, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dp, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dAxp, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&dAxr, n * sizeof(float)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\t\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(n, n, sizeof(float), A, n, dA, n));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(float), b, 1, db, 1));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(float), x, 1, dx, 1));\n","\n","\t// CG\n","\t\n","\t// TODO\n","\n","\t// final solution\n","\tfloat *y = (float *) malloc(sizeof(float) * n);\n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(float), dx, 1, x, 1));\n","\tcublasSgemv(handle, CUBLAS_OP_N, n, n, &one, dA, n, dx, 1, &zero, db, 1);   // b = 𝐴∗𝑥\n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(float), db, 1, y, 1));                // y = b\n","\n","\tplot_vec(n, b, 'b');\n","\tplot_vec(n, y, 'y');\n","\n","  free(A);\n","  free(x);\n","  free(b);\n","  cudaFree(dA);\n","  cudaFree(dx);\n","\tcudaFree(db);\n","  cudaFree(dr);\n","}\n","\n","void generate_random_simmetric_matrix(int n, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * n * n);\n","\n","\tfor (int r = 0; r < n-1; r++)\n","\t\tfor (int c = r; c < n; c++) {\n","      float val = (float)rand() / RAND_MAX;\n","\t\t\ta[IDX2R(r,c,n)] = val;\n","      a[IDX2C(r,c,n)] = val;\n","      val += 1;\n","\t\t}\n","\t*A = a;\n","}\n","\n","void plot_mat(int n, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < n; ++r){\n","    for(int c = 0; c < n; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,n)]);\n","    printf(\"\\n\");\n","\t} \n","  printf(\"\\n\");\n","}\n","\n","void plot_vec(int n, float *x, char name) {\n","  printf(\"\\nShow vec %c...\\n\", name);\n","\tfor(int i = 0; i < n; ++i)\n","\t\t\tprintf(\"%4.1f \", x[i]);\n","  printf(\"\\n\");\n","}\n","\n","void generate_random_vector(int n, float **x) {\n","\tfloat *z = (float *) malloc(sizeof(float) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (float)rand() / RAND_MAX;\n","\t*x = z;\n","}"],"metadata":{"id":"i5zDpZBgxOeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_37 cublas/CG.cu  -o CG -lcublas\n","!./CG"],"metadata":{"id":"5BZPf-gK0kJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# ✅ cuRAND\n"]},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%writefile curand/PI_kernel_MC.cu\n","\n","#include <stdio.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../../utils/common.h\"\n","\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float pi_mc_CPU(long trials) {\n","\tlong points_in_circle = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = rand() / (float) RAND_MAX;\n","\t\tfloat y = rand() / (float) RAND_MAX;\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\treturn 4.0f * points_in_circle / trials;\n","}\n","\n","__global__ void pi_mc_GPU(float *estimate, curandState *states) {\n","\tunsigned int tid = threadIdx.x + blockDim.x * blockIdx.x;\n","\tint points_in_circle = 0;\n","\tcurand_init(tid, 0, 0, &states[tid]);\n","\tfor (int i = 0; i < TRIALS_PER_THREAD; i++) {\n","\t\tfloat x = curand_uniform(&states[tid]);\n","\t\tfloat y = curand_uniform(&states[tid]);\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\testimate[tid] = 4.0f * points_in_circle / (float) TRIALS_PER_THREAD;\n","}\n","\n","/*\n"," * MAIN: MC method\n"," */\n","int main(void) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tdouble iStart = seconds();\n","\tfloat pi_cpu = pi_mc_CPU(THREADS * BLOCKS * TRIALS_PER_THREAD);\n","\tdouble iElaps = seconds() - iStart;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of PI = %f [error of %f]\\n\", pi_cpu, abs(pi_cpu - PI));\n","\n","\t// GPU procedure\n","\tcurandState *devStates;\n","\tcudaMalloc((void **) &dev, BLOCKS * THREADS * sizeof(float));\n","\tcudaMalloc((void **) &devStates, BLOCKS * THREADS * sizeof(curandState));\n","\tcudaEventRecord(start);\n","\tpi_mc_GPU<<<BLOCKS, THREADS>>>(dev, devStates);\n","  cudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tcudaMemcpy(host, dev, BLOCKS * THREADS * sizeof(float), cudaMemcpyDeviceToHost);\n","\tfloat pi_gpu = 0.0;\n","\tfor (int i = 0; i < BLOCKS * THREADS; i++)\n","\t\tpi_gpu += host[i];\n","\tpi_gpu /= (BLOCKS * THREADS);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"\\nGPU elapsed time (curand Monte Carlo): %.5f (sec)\\n\", milliseconds / 1000);\n","\tprintf(\"GPU estimate of PI = %f [error of %f ]\\n\", pi_gpu, abs(pi_gpu - PI));\n","  printf(\"Speed-up           = %.0f\\n\", iElaps/milliseconds*1000);\n","\tcudaFree(dev);\n","\tcudaFree(devStates);\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_37 curand/PI_kernel_MC.cu  -o mc_PI\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLcGSW8rqa9j"},"source":["%%writefile curand/PI_host_MC.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <curand.h>\n","#include \"../../utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","int main(void) {\n","    \n","\tlong trials = THREADS * BLOCKS * TRIALS_PER_THREAD; // num points\n","\n","  printf(\"Number of random points in the square = %lu\\n\", trials);\n","\n","\tcurandGenerator_t gen;\n","\tfloat *X_d, *X, *Y_d, *Y ;\n","\n","\t// Allocate points on host\n","\tX = (float *) malloc(trials * sizeof(float));\n","  Y = (float *) malloc(trials * sizeof(float));\n","\n","\t/* Allocate n floats on device */\n","\tCHECK(cudaMalloc((void **)&X_d, trials * sizeof(float)));\n","  CHECK(cudaMalloc((void **)&Y_d, trials * sizeof(float)));\n","\n","\t// Create pseudo-random number generator \n","\tCHECK_CURAND(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n","\n","\t// Set seed \n","\tCHECK_CURAND(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n","\n","\t// Generate 2*n floats on device \n","\tCHECK_CURAND(curandGenerateUniform(gen, X_d, trials));\n","  CHECK_CURAND(curandGenerateUniform(gen, Y_d, trials));\n","\n","\t// Copy device memory to host \n","\tCHECK(cudaMemcpy(X, X_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","  CHECK(cudaMemcpy(Y, Y_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  // num of points within the circle\n","  ulong points_in_circle = 0;\n","  for (long i = 0; i < trials; i++) \n","\t\tpoints_in_circle += (X[i] * X[i] + Y[i] * Y[i] <= 1.0f);\n","\n","  // estimate PI\n","\tfloat pi = 4.0f * points_in_circle / (float)trials;\n","  printf(\"Estimate of PI = %f [error of %f]\\n\", pi, abs(pi - PI));\n","\n","\t// Cleanup \n","\tCHECK_CURAND(curandDestroyGenerator(gen));\n","\tCHECK(cudaFree(X_d));\n","  CHECK(cudaFree(Y_d));\n","  free(X);\n","\tfree(Y);\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_37 curand/PI_host_MC.cu -o mc_PI -lcurand\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 TODO"],"metadata":{"id":"O2AFWRhsw2XO"}},{"cell_type":"code","metadata":{"id":"UcVvtvNN3-3V"},"source":["%%writefile curand/Gauss_MC.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../../utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float Gauss_CPU(long trials, float a, float b, float max) {\n","\tlong s = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = (b-a)*(rand() / (float) RAND_MAX)+a;\n","\t\tfloat y = (rand() / (float) RAND_MAX);\n","\t\ts += (y <= expf(-x*x/2));\n","\t}\n","\treturn s / (float)trials;\n","}\n","\n","__global__ void Gauss_GPU(float *estimate, curandState *states, float a, float b, float max) {\n","\t // TODO\n","}\n","\n","int main(int argc, char *argv[]) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\tfloat a = -1;\n","\tfloat b = 2;\n","\tfloat max = 1.0f/sqrt(2*PI);\n","\tfloat A = (b-a)*max;\n","\tfloat P_true = 0.818594;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tdouble iStart = seconds();\n","\tlong N = THREADS * BLOCKS * TRIALS_PER_THREAD;\n","\tfloat P_cpu = Gauss_CPU(N,a,b,max);\n","\tdouble iElaps = seconds() - iStart;\n","\tP_cpu = P_cpu*A;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of P = %f [error of %f]\\n\", P_cpu, abs(P_cpu - P_true));\n","\n","\t// GPU procedure\n","\t\n","\t// TODO\n","\t\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCLXnW_34NPf"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_37 curand/Gauss_MC.cu -o Gauss_MC\n","!./Gauss_MC"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ✅ cuFFT"]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%writefile cufft/cufft.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cufft.h>\n","#include \"../../utils/common.h\"\n","\n","#define BATCH 16\n","\n","/*\n"," * An example usage of the cuFFT library. This example performs a 1D forward\n"," * FFT.\n"," */\n","\n","int nprints = 30;\n","\n","/*\n"," * Create N fake samplings along the function cos(x). These samplings will be\n"," * stored as single-precision floating-point values.\n"," */\n","void generate_fake_samples(int N, float **out) {\n","\tint i;\n","\tfloat *result = (float *) malloc(sizeof(float) * N);\n","\tdouble delta = M_PI / 20.0;\n","\tfor (i = 0; i < N; i++)\n","\t\tresult[i] = cos(i * delta);\n","\t*out = result;\n","}\n","\n","void rect(uint N, float **out) {\n","\tfloat *r = (float *) calloc(N, sizeof(float));\n","\tfor (uint i = 0; i < N/100; ++i) \n","    r[i] = 1.0f;\n","\t*out = r;\n","}\n","\n","/*\n"," * Convert a real-valued vector r of length Nto a complex-valued vector.\n"," */\n","void real_to_complex(float *r, cufftComplex **complx, int N) {\n","\tint i;\n","\t(*complx) = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\tfor (i = 0; i < N; i++) {\n","\t\t(*complx)[i].x = r[i];\n","\t\t(*complx)[i].y = 0;\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\n","\tint i;\n","\tint N = 1024*1024;\n","\tfloat *samples;\n","\tcufftHandle plan = 0;\n","\tcufftComplex *dComplexSamples, *complexSamples, *complexFreq;\n","\n","\t// Input Generation\n","\trect(N, &samples);\n","\n","  printf(\"Start computation...\\n\");\n","  double start = seconds();\n","\treal_to_complex(samples, &complexSamples, N);\n","\t\n","  complexFreq = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\t// Setup the cuFFT plan\n","\tCHECK_CUFFT(cufftPlan1d(&plan, N, CUFFT_C2C, 1));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dComplexSamples, sizeof(cufftComplex) * N));\n","\n","\t// Transfer inputs into device memory\n","\tCHECK(cudaMemcpy(dComplexSamples, complexSamples, sizeof(cufftComplex) * N, cudaMemcpyHostToDevice));\n","\n","\t// Execute a complex-to-complex 1D FFT\n","\tCHECK_CUFFT(cufftExecC2C(plan, dComplexSamples, dComplexSamples, CUFFT_FORWARD));\n","\n","\t// Retrieve the results into host memory\n","\tCHECK(cudaMemcpy(complexFreq, dComplexSamples, sizeof(cufftComplex) * N, cudaMemcpyDeviceToHost));\n","\n","  double elaps = seconds() - start;\n","\n","  printf(\"Elapsed time: %f (sec)\\n\", elaps);\n","\n","  // save FFT on a file\n","  printf(\"Save on file...\\n\");\n","  FILE *filePtr;\n","  filePtr = fopen(\"FFTdata.txt\",\"w\");\n","  for (i = 0; i < N; i++) {\n","    fprintf(filePtr, \"%.3g, %.5g\\n\", complexFreq[i].x, complexFreq[i].y);\n","  }\n"," \n","\tfree(samples);\n","\tfree(complexSamples);\n","\tfree(complexFreq);\n","\n","\tCHECK(cudaFree(dComplexSamples));\n","\tCHECK_CUFFT(cufftDestroy(plan));\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_37 cufft/cufft.cu -o fft -lcufft\n","!./fft"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPU4iiE7LT59"},"source":["# python code: read FFT data file and plot the FFT magnitude\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# read file\n","Xlist = [] \n","Ylist = []\n","with open(\"FFTdata.txt\", \"r\") as f:\n","  for line in f.readlines():\n","    x,y = line.split(\",\")\n","    Xlist.append(float(x))\n","    Ylist.append(float(y))\n","\n","# compute magnitude\n","X = np.power(Xlist,2)\n","Y = np.power(Ylist,2)\n","F = np.sqrt(X+Y)\n","\n","# plot\n","plt.subplots(figsize=(10, 6))\n","plt.plot(F[:500])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ Python"],"metadata":{"id":"l1rqW0qCN4YD"}},{"cell_type":"markdown","metadata":{"id":"n7s0fNhj8MK5"},"source":["Basics of CuPy\n","In this section, you will learn about the following things:\n","\n","- Basics of cupy.ndarray\n","\n","- The concept of current device\n","\n","- Host-device and device-device array transfer\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eTnzYTT-8Ydu"},"source":["CuPy is a GPU array backend that implements a subset of NumPy interface. In the following code, `cp` is an abbreviation of `cupy`, following the convention of abbreviating `numpy` to `np`:"]},{"cell_type":"code","metadata":{"id":"Vwk0mIU260-T"},"source":["import numpy as np\n","import cupy as cp\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HskcLFHP8a9f"},"source":["The `cupy.ndarray` class is in its core, which is a compatible GPU alternative of `numpy.ndarray`."]},{"cell_type":"code","metadata":{"id":"EW7Juf-265nJ"},"source":["x_gpu = cp.array([1, 2, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7GnwT-3X8vRG"},"source":["`x_gpu` in the above example is an instance of `cupy.ndarray`. You can see its creation of identical to NumPy’s one, except that `numpy` is replaced with `cupy`. The main difference of `cupy.ndarray` from `numpy.ndarray` is that the content is allocated on the device memory. Its data is allocated on the current device, which will be explained later.\n","\n","Most of the array manipulations are also done in the way similar to NumPy. Take the Euclidean norm (a.k.a L2 norm) for example. NumPy has `numpy.linalg.norm()` to calculate it on CPU."]},{"cell_type":"code","metadata":{"id":"w9JcohVT81HS"},"source":["x_cpu = np.array([1, 2, 3])\n","l2_cpu = np.linalg.norm(x_cpu)\n","print(l2_cpu)\n","\n","x_gpu = cp.array([1, 2, 3])\n","l2_gpu = cp.linalg.norm(x_gpu)\n","print(l2_gpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ViTanoJN9I0_"},"source":["CuPy has a concept of current devices, which is the default device on which the allocation, manipulation, calculation, etc., of arrays are taken place. Suppose the ID of current device is 0. The following code allocates array contents on GPU 0."]},{"cell_type":"code","metadata":{"id":"iBg3heve9PCq"},"source":["x_on_gpu0 = cp.array([1, 2, 3, 4, 5])\n","# cp.cuda.Device(1).use() # trigger dev 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q7drGpfb9wCU"},"source":["__Move arrays to a device__ \n","\n","`cupy.asarray()` can be used to move a `numpy.ndarray`, a `list`, or any `object` that can be passed to `numpy.array()` to the current device:"]},{"cell_type":"code","metadata":{"id":"KvD5Dc9r923D"},"source":["x_cpu = np.array([1, 2, 3])\n","x_gpu = cp.asarray(x_cpu)  # move the data to the current device."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PXUrXI0T-ESO"},"source":["`cupy.asarray()` can accept `cupy.ndarray`, which means we can transfer the array between devices with this function."]},{"cell_type":"markdown","metadata":{"id":"XsUNmrVt-egt"},"source":["__Move array from a device to the host__\n","\n","Moving a device array to the host can be done by `cupy.asnumpy()` as follows:"]},{"cell_type":"code","metadata":{"id":"7HCC9Xot-jfO"},"source":["x_gpu = cp.array([1, 2, 3])  # create an array in the current device\n","x_cpu = cp.asnumpy(x_gpu)  # move the array to the host.\n","\n","# We can also use cupy.ndarray.get():\n","x_cpu = x_gpu.get()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ya5ZUuX5_Qyi"},"source":["__How to write CPU/GPU agnostic code__\n","\n","The compatibility of CuPy with NumPy enables us to write CPU/GPU generic code. It can be made easy by the `cupy.get_array_module()` function. This function returns the numpy or cupy module based on arguments. A CPU/GPU generic function is defined using it like follows:\n","\n"]},{"cell_type":"code","metadata":{"id":"m41F-1Tu_UQz"},"source":["# Stable implementation of log(1 + exp(x))\n","def softplus(x):\n","  xp = cp.get_array_module(x)\n","  return xp.maximum(0, x) + xp.log1p(xp.exp(-abs(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFq4cQEM_lBL"},"source":["Sometimes, an explicit conversion to a host or device array may be required. `cupy.asarray()` and `cupy.asnumpy()` can be used in agnostic implementations to get host or device arrays from either CuPy or NumPy arrays."]},{"cell_type":"code","metadata":{"id":"BjpD_S2pACgb"},"source":["y_cpu = np.array([4, 5, 6])\n","x_cpu + y_cpu\n","x_gpu + y_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_FzwiWg_ogl"},"source":["cp.asnumpy(x_gpu) + y_cpu\n","cp.asnumpy(x_gpu) + cp.asnumpy(y_cpu)\n","x_gpu + cp.asarray(y_cpu)\n","cp.asarray(x_gpu) + cp.asarray(y_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cupy demo"],"metadata":{"id":"WcfingSvOvQN"}},{"cell_type":"markdown","source":["* CuPy implements the multi-dimensional array of numpy on CUDA.\n","* CuPy has a large community of developers (on github),\n","under the direction by the company Preferred Networks.\n","* CuPy uses on-the-fly kernel synthesis:\n","for a required kernel call, it compiles the code of the kernel,\n","optimizes for shapes and dtypes of the arguments;\n","sends the compiled code to the GPU device; and\n","executes the kernel.\n","* The kernel code is cached, so the second call executes faster."],"metadata":{"id":"xWEf8_LOQfT7"}},{"cell_type":"code","source":["### Numpy and CPU\n","s = time.time()\n","x_cpu = np.ones((1000,1000,1000))\n","e = time.time()\n","print(f\"CPU: {e-s}\")\n","\n","### CuPy and GPU\n","s = time.time()\n","x_gpu = cp.ones((1000,1000,1000))\n","cp.cuda.Stream.null.synchronize()\n","e = time.time()\n","print(f\"GPU: {e-s}\")"],"metadata":{"id":"lENNIpGJMP1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Numpy and CPU\n","s = time.time()\n","x_cpu *= 5\n","e = time.time()\n","print(f\"CPU: {e-s}\")\n","\n","### CuPy and GPU\n","s = time.time()\n","x_gpu *= 5\n","cp.cuda.Stream.null.synchronize()\n","e = time.time()\n","print(f\"GPU: {e-s}\")"],"metadata":{"id":"JAnklGBAMVVT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5n9B3KKsNEzC"},"execution_count":null,"outputs":[]}]}